{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numerapi\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import yfinance\n",
    "\n",
    "\n",
    "import simplejson\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests as re\n",
    "import datetime\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "NAPI_PUBLIC_KEY = os.environ[\"PUBLIC_ID\"]\n",
    "NAPI_PRIVATE_KEY = os.environ[\"SECRET_ID\"]\n",
    "napi = numerapi.SignalsAPI(NAPI_PUBLIC_KEY, NAPI_PRIVATE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27407482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\n",
    "    f\"signals/v1.0/train.parquet\"\n",
    ")\n",
    "\n",
    "df_validation = pd.read_parquet(\n",
    "    f\"signals/v1.0/validation.parquet\"\n",
    ")\n",
    "\n",
    "ticket = list(set(df_train[\"numerai_ticker\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.concat([df_train,df_validation])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e80cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ticker_counts_per_date(df, title, color_column):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Count unique 'numerai_ticker' per 'date'\n",
    "    nticker_count_per_date = df.groupby('date')['numerai_ticker'].nunique().reset_index(name='numerai_ticker_count')\n",
    "\n",
    "    # Check if color_column exists in the DataFrame\n",
    "    if color_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{color_column}' not found in the DataFrame\")\n",
    "\n",
    "    # Map categorical values to colors\n",
    "    unique_categories = df[color_column].unique()\n",
    "    color_map = {cat: plt.cm.tab10(i / len(unique_categories)) for i, cat in enumerate(unique_categories)}\n",
    "    \n",
    "    # Add colors to the DataFrame\n",
    "    df['color'] = df[color_column].map(color_map)\n",
    "    \n",
    "    # Merge colors into the counts DataFrame\n",
    "    color_map_per_date = df.drop_duplicates(subset=['date', color_column]).set_index('date')['color'].to_dict()\n",
    "    nticker_count_per_date['color'] = nticker_count_per_date['date'].map(color_map_per_date)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(nticker_count_per_date['date'], nticker_count_per_date['numerai_ticker_count'], \n",
    "                c=nticker_count_per_date['color'], edgecolor='k', marker='o')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Add legend\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=cat, \n",
    "                          markersize=10, markerfacecolor=color_map[cat]) \n",
    "               for cat in unique_categories]\n",
    "    plt.legend(handles=handles, title=color_column)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ticker_counts_per_date(df_final, 'Ticker Counts per Date', 'data_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eligible_tickers = pd.Series(napi.ticker_universe(), name='ticker') \n",
    "\n",
    "eligible_tickers = pd.Series(list(set(df_final[\"numerai_ticker\"])), name='ticker') \n",
    "print(f\"Number of eligible tickers: {len(eligible_tickers)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_us=[x for x in eligible_tickers if \"GOOGL\" in x]\n",
    "list_us\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3addd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_ticket_yahoo(x):\n",
    "    x=x.split(\" \")[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe140102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"prueba\"]=df_final[\"numerai_ticker\"].apply(extraer_ticket_yahoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_tickers = pd.Series(list(set(df_final[\"prueba\"])), name='ticker') \n",
    "print(f\"Number of eligible tickers: {len(eligible_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 600  #chunk row size\n",
    "chunk_df = [yfinance_tickers.iloc[i:i+n] for i in range(0, len(yfinance_tickers), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ed84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_top_five_sp500 = [\"AAPL\",\"MSFT\",\"GOOGL\",\"AMZN\",\"TSLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c94f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat(concat_dfs)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_parquet('yahoo/datos_yahoo.parquet')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.columns = ['date', 'ticker', 'price']\n",
    "full_data.set_index('date', inplace=True)\n",
    "\n",
    "# convert yahoo finance tickers back to numerai tickers\n",
    "full_data['ticker'] = full_data.ticker.map(dict(zip(yfinance_tickers, numerai_tickers)))\n",
    "\n",
    "print(f\"Number of tickers with data: {len(full_data.ticker.unique())}\")\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(prices, interval=14):\n",
    "  '''Computes Relative Strength Index given a price series and lookback interval\n",
    "  Modified from https://stackoverflow.com/questions/20526414/relative-strength-index-in-python-pandas\n",
    "  See more here https://www.investopedia.com/terms/r/rsi.asp'''\n",
    "  delta = prices.diff()\n",
    "\n",
    "  dUp, dDown = delta.copy(), delta.copy()\n",
    "  dUp[dUp < 0] = 0\n",
    "  dDown[dDown > 0] = 0\n",
    "\n",
    "  RolUp = dUp.rolling(interval).mean()\n",
    "  RolDown = dDown.rolling(interval).mean().abs()\n",
    "\n",
    "  RS = RolUp / RolDown\n",
    "  RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "  return RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_groups = full_data.groupby('ticker')\n",
    "full_data['RSI'] = ticker_groups['price'].transform(lambda x: RSI(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b892c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = full_data.groupby(full_data.index)\n",
    "date_groups['RSI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, group in date_groups:\n",
    "    print(f\"Date: {date}\")\n",
    "    print(group['RSI'])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = full_data.groupby(full_data.index)\n",
    "full_data['RSI_quintile'] = date_groups['RSI'].transform(lambda group: pd.qcut(group, 5, labels=False, duplicates='drop'))\n",
    "full_data.dropna(inplace=True)\n",
    "\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_groups = full_data.groupby('ticker')\n",
    "\n",
    "#create lagged features, lag 0 is that day's value, lag 1 is yesterday's value, etc\n",
    "num_days = 5\n",
    "for day in range(num_days+1):\n",
    "    full_data[f'RSI_quintile_lag_{day}'] = ticker_groups['RSI_quintile'].transform(lambda group: group.shift(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8cec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(num_days):\n",
    "    full_data[f'RSI_diff_{day}'] = full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}']\n",
    "    full_data[f'RSI_abs_diff_{day}'] = np.abs(full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f'RSI_quintile_lag_{num}' for num in range(num_days)] + [f'RSI_diff_{num}' for num in range(num_days)] + [f'RSI_abs_diff_{num}' for num in range(num_days)]\n",
    "print(f'Features for training:\\n {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8499140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.rename(columns={'numerai_ticker': 'ticker'})\n",
    "\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2847654",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_data = pd.merge(df_train, full_data.reset_index(), on=['date','ticker'], how=\"left\").set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrado=ML_data[(ML_data[\"price\"].isna()) & (ML_data[\"ticker\"]==\"MSFT US\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorized_mean(series, limits=(0.05, 0.05)):\n",
    "    if series.dropna().empty:\n",
    "        return float('nan')  # O un valor predeterminado apropiado\n",
    "    winsorized_series = winsorize(series.dropna(), limits=limits)\n",
    "    return pd.Series(winsorized_series).mean()\n",
    "\n",
    "# Aplicar winsorization para cada ticker\n",
    "def calculate_winsorized_means(group):\n",
    "    return winsorized_mean(group['price'], limits=(0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dea960",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorized_means = ML_data.groupby('ticker').apply(calculate_winsorized_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e82dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorized_means.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef427189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "tensor_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
